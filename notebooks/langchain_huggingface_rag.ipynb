{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain using Huggingface models - RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/babi/miniconda3/envs/tenx_week7/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-02-03 12:21:19.520563: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-03 12:21:19.520603: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-03 12:21:19.521487: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-03 12:21:19.527050: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-03 12:21:20.712448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/babi/miniconda3/envs/tenx_week7/lib/python3.11/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/babi/miniconda3/envs/tenx_week7/lib/python3.11/site-packages/torch/cuda/__init__.py:740: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter  \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.vectorstores import Weaviate\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "from langchain import HuggingFacePipeline\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline, BitsAndBytesConfig, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "from typing import List, Optional, Union\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "iocuydi/llama-2-amharic-3784m does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miocuydi/llama-2-amharic-3784m\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tenx_week7/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:484\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    483\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tenx_week7/lib/python3.11/site-packages/transformers/modeling_utils.py:2555\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2549\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2550\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2551\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but there is a file without the variant\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2552\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvariant\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Use `variant=None` to load this model from those weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2553\u001b[0m             )\n\u001b[1;32m   2554\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2555\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2556\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2557\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2558\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFLAX_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2559\u001b[0m             )\n\u001b[1;32m   2560\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m   2561\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted\u001b[39;00m\n\u001b[1;32m   2562\u001b[0m     \u001b[38;5;66;03m# to the original exception.\u001b[39;00m\n\u001b[1;32m   2563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: iocuydi/llama-2-amharic-3784m does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack."
     ]
    }
   ],
   "source": [
    "model_name = \"iocuydi/llama-2-amharic-3784m\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "# embedding_model_name = \"sentence-transformers/clip-ViT-B-32\"\n",
    "# embedding_model_name = \"sentence-transformers/average_word_embeddings_komninos\"\n",
    "# embedding_model_name = \"iocuydi/llama-2-amharic-3784m\"\n",
    "\n",
    "model_kwargs = {}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "  model_name=embedding_model_name, \n",
    "  model_kwargs=model_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(file_path: str, chunk_size: int = 500, chunk_overlap: int = 50) -> Union[List[str], None]:\n",
    "    \"\"\"\n",
    "    Load data from a file, split it into chunks, and return the chunks.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The path to the file containing the data.\n",
    "    - chunk_size (int): The size of each data chunk. Default is 500.\n",
    "    - database (int): The overlap between consecutive chunks. Default is 50.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of data chunks.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        loader = TextLoader(file_path)\n",
    "        documents = loader.load()\n",
    "\n",
    "        # Chunk the data\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        \n",
    "        print(\"Data loaded to vector database successfully\")\n",
    "        return chunks\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None \n",
    "    \n",
    "    \n",
    "def create_retriever(chunks):\n",
    "   try:\n",
    "    #    Setup vector database\n",
    "       client = weaviate.Client(embedded_options=EmbeddedOptions())\n",
    "\n",
    "       # Populate vector database using embeddings from the Hugging Face model\n",
    "       vectorstore = Weaviate.from_documents(\n",
    "           client=client,\n",
    "           documents=chunks,\n",
    "           embedding=embeddings,  # Use the model's encode function for embeddings\n",
    "           by_text=False\n",
    "       )\n",
    "\n",
    "       # Define vectorstore as retriever to enable semantic search\n",
    "       retriever = vectorstore.as_retriever()\n",
    "       print(\"Retriever created successfully.\")\n",
    "\n",
    "       return retriever\n",
    "\n",
    "   except Exception as e:\n",
    "       print(f\"An unexpected error occurred: {e}\")\n",
    "       return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and create chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded to vector database successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chuncks = data_loader(\"../prompts/context.txt\")\n",
    "len(chuncks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/babi/miniconda3/envs/tenx_week7/lib/python3.11/site-packages/weaviate/warnings.py:158: DeprecationWarning: Dep016: You are using the Weaviate v3 client, which is deprecated.\n",
      "            Consider upgrading to the new and improved v4 client instead!\n",
      "            See here for usage: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            \n",
      "  warnings.warn(\n",
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-02-03T12:21:43+03:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-02-03T12:21:43+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-02-03T12:21:44+03:00\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /home/babi/.cache/weaviate-embedded: process ID 218546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-02-03T12:21:44+03:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50060\",\"time\":\"2024-02-03T12:21:44+03:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-02-03T12:21:44+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_0a43cce8a9f54813a3ad4f3d498d6434_NISdUtmHet4a in 12.697056ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":106241}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_0312ef7773c64bd5a9d3d2ba96f090fb_0TLKGeLxTnEG in 52.510427ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":116783}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_133fb572c0784fe9b7544b27354d2e3a_4kCtu55fH4aJ in 82.067905ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":114715}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_2287c33037f843a0a691ee7c3ca217ff_UHNPzeo6TFps in 77.343863ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":108505}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_198c544d7c454b1eb547b172cbd3d3f2_Zoub04C5GCZy in 79.469752ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":120877}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_26666663df8145759ff4ae05bfd0b380_ZErds8qG0OhT in 79.11783ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":111516}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_698f357610544f228bc230b3c3c1c248_yHzTxe2uDT3I in 76.959643ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":117596}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_12d21afc8bd941749f3413f7862f3a0e_LJQY2or5Gsvq in 90.977086ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":116792}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_9ef38c5f9b6541ce803b756a43c4f2c8_H51zBeBv8ZGC in 77.819891ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":118515}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_7935ba202d2d46859491fec093850b98_b3zZJgFFSvL1 in 109.486873ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":116164}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_b3743bfe41ae4f54a2f9419c91f60511_oBMpY4s7j7gS in 102.758361ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_30a7ed705d2241cdbd1ad4f88e8983a8_SoweZG10lzhr in 112.698196ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":113362}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":108214}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_58545170b3b84b29896475d83524695a_pLaXH0W2gCyA in 114.834292ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_e8de4dcac47249479063752b57b77c8a_hSFnzwKm5OzZ in 98.018824ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_b97061b7057d40be932b575ce78505c3_9RcINbV8bmFI in 103.543596ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":116763}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":104773}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_a82a03a728dd4873b47137ecec1996da_X880GrXTzAmC in 105.246086ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":111668}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":817170}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_ca8ec0bb08804f2f855837a6932b5460_hBfuKUptHV8z in 103.240163ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":117371}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_fcc9bc095d134228bb9b7ff8e5f9dd3e_5ImU9dQmww41 in 98.755409ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":109004}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_00b249fe17924277a770d96c9dcbaff0_tfPI911fNk1H in 128.534286ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_27909b9fdb7a488d8ff0a8d01137ed9a_IFose2oTztrN in 117.183609ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_5c4e41b7421a4647985e5533c3d52445_Xiw5kXoCgxG9 in 117.497946ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":114019}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":194016}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_5125cd6873384faa9eb7e1ce526d7323_ZPDkffgDLlLD in 118.629066ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":111581}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":614624}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_094829e85d36449ab3b283e1ac2fbf04_vqcZmuLhfJ9y in 128.71124ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":402802}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_044064392d3242a8a33f73f528a27f1d_92wb8jcjigPk in 129.191484ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":262938}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_295312e7406a4ee0b553860a79366b18_jW5tizyQXsZ3 in 120.4485ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":163727}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_50957979f294425586dea6a1fc969dbd_jjAnWw4sTNE0 in 114.482114ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_fdfed8d23d1a4ed68f96696c92af7b45_azU29epaDNmO in 102.756877ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":184373}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":178120}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_e96d64b20f0847159e3f8e1a541a9a6d_7xqZq61YOfAj in 104.664074ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":113986}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_fdee1dcd1aa348acac39bccdbdaddd81_R7hDToyb91tX in 103.224008ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":100740}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_79e2deca675b44f1b61e27b674dd9659_urhVawsDj8pD in 117.865117ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_fcfb1cbd9912404381cc799ee156efdd_nRPGpzz1KPLm in 103.575538ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":108937}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":112297}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_c7caa635303c448e95b5f71ba08b2956_aFk0U0CKJvlt in 108.85985ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":110175}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_66b4400d9994425ca7e1eb543bcb3041_MpzRapwC4z4d in 120.631384ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_b8f5c020dad8424995a257c897db47d6_zob2dDuslGFs in 111.732696ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":116463}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":151375}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_4b51e0a56e34429294183d836886bbf5_chZtzv3vlG0X in 119.484793ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_6d770baf40a84c93824e03a28cb7f5dc_0xSq7UdVBXTv in 119.391272ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":125214}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_3befa79eada749aea183be1ebacf70bd_WMM4etojJlF5 in 125.645654ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_0b81d9e3eaff430ca773ae73e8746670_O2AHC9ofO3bw in 126.33325ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":144322}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_2a1799d0d2e64a7caaf0555f78a153c5_pf7MdKvEjIY6 in 124.740421ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":757520}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":106744}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_ac8d1707c3e14e42b2f3bb65ab8540f3_fgTj1UOo3Lyl in 115.791097ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":81541}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":742133}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_239d2792dc5e4e2abbb2c8c36f96f9c2_j3K0Ny9bkKfi in 126.34538ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":84585}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_65be063dba3848e38702e345579822c0_gFAXJdvR3HpP in 125.699615ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":94564}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_4836fb590cb1419ea6656a040c488d24_gsB3Y5XuzcXk in 124.111095ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":161572}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_496a3e4e7bf94f77b1ddf43b9f7cec85_rqWMZQKSavMl in 124.149305ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":141474}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_94318bbb3db241aba328b2891fd99d6c_zIkOarNqfoeG in 122.585218ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_de5d55a3095e481dbfc34a24ec843b6a_FTy1BMOnh1Ky in 114.677333ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":98116}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_83bb50859fcf4f7dbda201a126101d39_GjLVFWvBwn0m in 124.627562ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":108011}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":81283}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_c0d3b805a92741a3b7c67f0d5ba1cfd2_kyK609sNogOA in 119.88134ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":90721}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_3773278af3bf44c6974be51681bd1435_rGM6mbuHbah4 in 132.157054ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":144320}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_8e4321718d2c46bd9d6cc0363aa3b8a1_QJa2AEzabs8Z in 129.040179ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_28f3bb7c9b5247ca9a2432f01796c027_a8dhg0N9Rrpj in 132.162125ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":126705}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_6492b867fd5b4cd1a1d2ca1037275f75_cFPS9aq2Kfg4 in 128.095257ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_77882a7b8ff44da5b9929c98bdec7c76_3geFmBVwtOY2 in 132.268466ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":166866}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":86752}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_511e4a61e99c42ff8ddbda98ae195428_hMU6FHFI4gwo in 136.870899ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":122257}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_c2681a8ffc76420db9d8028730a9c2ed_UFUgjBBDPgWg in 124.312899ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_5cc378ce712242cb949dddc4f21272e9_UbULVzx44tL3 in 136.993547ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":601788}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":650665}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_180a289e3574490dbf5430c128d823ac_c7nS9G1DHDLZ in 147.408191ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_b7a0bda536a0440180ce6d5bb90cf02d_wrktB5e6743b in 127.502948ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_a04ff10c00ed45a1b68617e26958c8fb_EpIpwcDZiTnO in 130.650323ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":79191}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":116691}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_4c2cbdac9fa443eaad4180687ee65e16_x6UxCHGUC7kR in 133.585558ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":135172}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_a0795a009713456ca35fb1fb03d0eb02_9pzvFtVa9APs in 130.095812ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":329561}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":117524}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_4f54e6dd9a024ca384b0132696f824a0_LTZnrIDTjSlN in 139.856008ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":125020}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_6a3dea270c9d4a788ccf2eb5302e611c_prL77N0mdnFc in 130.922494ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_bfaff2a87a6e4702a0d2e8b9266c84cd_4mJJfq4i1k3P in 126.638276ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":83653}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_27dcfe368f6b4d958ffa669f7933d370_l6OE6laKks9L in 141.21179ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":123345}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_efd4b1af5afa4129a4158d5de2e56ddf_Usx5vQLJoAsW in 123.781868ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":121211}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":125806}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":152860}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_19638f81ce5d4b4e9b9413567833f7ce_G1GroA34q0mL in 141.161283ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":112523}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_c7ebacded851432ebd6b05481777f742_yIxMeF55G4YQ in 128.093798ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_65398c7e512343e69318d8a32888d668_NWaXuCxew4i9 in 132.587423ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":168495}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_64e8bc4c10c144a2ad58860149b405d1_86sJWLTUFxo5 in 133.509652ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":77502}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_de020582bc7c47ff94750419fe27bc0a_ZaPywvohnTsX in 127.104635ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":90828}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_1f41348bf9cd4390b44def9261cf2bc8_XKxlbIuwtk65 in 143.400922ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_9ad5ae5cc05e4e3da5ce4b05f57fdd64_ab3kpDhXe37j in 135.328136ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_653cbe3e6689480293e4a8215b930959_nlo2bDOgVacv in 133.784596ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":150138}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":770729}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":578295}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_1ce42fd9e730438cb975281984762d81_wiq6iQ2n0QO1 in 143.594692ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":672345}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_55f0a253d2b54ffbb5dafdb74bb364c4_qv00Sx8yhABB in 145.118162ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":289866}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_e79a626d630c42518cd11d6471b617f8_uvynfNGia2ly in 129.290698ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_4696c9c0bd674d0ca4fc2d7fe99b6bfa_pLeBhYvfVAC8 in 145.876512ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":135490}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":140022}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_af948f2a7ab9408c8520bb65e61e194e_TjXRAnf6gwlZ in 135.863017ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":132233}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_31b3c62caf52436c8ffad34e7acc9432_8ZwSHjkfby5d in 147.601572ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_3d6a800d823a4acdaae781ccbae32c89_Nhocx19uM59C in 142.704481ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":110674}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_7a9eceac92e2481bb0128bb2f88cec14_TSeosXpZyFRe in 143.78287ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":121699}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":547457}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_baa7b447464f4fdbb3aca5187cb22e74_dtviWxFZoxRT in 136.450898ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":114913}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_8c85d3c62b71451db3b80cc9bdb96ebf_0lgFexiA5hCi in 139.335219ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_432ee6dc833f4f6ebbbfb60aef908677_Ma54FlFUae9Q in 145.847993ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_e8be247f8f6845cdafe8b6affd2734f4_JtXVAls3BTra in 131.511478ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":86728}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":130421}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":537347}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_f6b64408a07142559dbd9fa9d395a5e3_aFu3VtJMTo8F in 130.415284ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_78ed6a839d3c4511afbea769d07fa4b4_tVW90pJotLEI in 139.412721ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_a6eba2f152244c3eb5656ab1e7af625f_6dNvW4KhHxxV in 139.600571ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_21b6e14060cc4d75a382e81ef06cd4c5_DXduIw4MvqFy in 149.332266ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":1968415}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":752829}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":127723}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":2006836}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_8f006eba61624113870add5dc417cf8d_5HsfjSDcNKRJ in 141.465518ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":659809}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":132435}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_3dae534c1d4b4e1d837fe6bf85642817_giWKfwQSgDlY in 148.607139ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":97238}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_d35e199e254f4befbfe814bf8c81bf00_G54pfNkYlnpf in 136.574255ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":90651}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_e48c08666514431698494c67ae945bb7_v4N0QpdDRDvN in 135.045217ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":85105}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_7b6349d24ab943339c53f093e3c158a9_5zhMpC0u9M4g in 171.980922ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_74180e2845d1477290b3d3c623314944_OuEkjxqNaofI in 178.491052ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":79383}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":108449}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_b9f4450563a54709ab32be6288d775a7_9VwJ8duTANxJ in 170.44754ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_a7e595f086f94b21ade6a8ae4d084d50_gwFtKePgZAHY in 172.596596ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_c520d9250a12450ba3b117cd6191ea8c_zOBi0ZYuLhhn in 168.843667ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":177149}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":238874}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":260563}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_e77729ad663b497aa676bf270f0c83a3_4Ffn1FVZwVF8 in 165.646421ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":118809}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_4d0a9a62ea9d447ab137ed1062a18e7f_qcocbx6c3vWD in 177.129563ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_249710fa43a04b028c6088aa0bcb5637_5JcTAjbnLlS2 in 182.401847ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":78635}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":79312}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_5ce0983842194bea9e99d259f65cc4a8_lE0K6y1kCAbu in 182.806315ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_a0d8ca61ea114c2baac96643e11e1860_xo4M26CFZDsA in 174.819672ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_7ab4e39a2959450f9d25c4f094c1ed65_RbKsTje6S11Q in 178.545926ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":248258}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":133913}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":649070}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_a136104104f14d6ab12f98e6d39d11ca_1sAiUUcGKQew in 174.831232ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":77468}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_af6aed16438d479a8de64da5c5e6ecc0_dkyxFf84TnHW in 172.382329ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_8c1807552a88411294e1c3c894e937c0_s5wCRaUUmhQI in 177.942286ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":110691}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":136317}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_8d9bdec16c4c4f6ba4e15d9eff33d295_Ogkj7MmeTiXz in 177.496744ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":144586}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_d6dae56133da45dcb51d06b11d3f0076_nXayLn0BUzjw in 170.482276ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_5fc955b930854bd0ab167a7b9d59f001_XZKVCSQkonBm in 177.314054ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_de50f0b9568f467c9384b78673f0683a_68nOA0yzrnRA in 169.398318ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":348687}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_dfad81fac8e04bf9a5dc95399e7c1293_mUFMm1hng3t7 in 169.701943ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_2f129bb8b4d346e49c6a6f615c27b9fc_iq9fUN2vBUo3 in 181.418467ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_a14bda61e6e546c4b5467a573018b800_RQzLugQEE3Ix in 176.019912ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":85285}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":137295}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":146860}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_25eba5d882d3483890db2a9db02aeb7d_4mehOMtoZRZL in 185.286746ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":164446}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_6f33a881c8a44172be4810d8caef00b7_DWxAhPY1dH9Y in 182.57925ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_8067657dfd384c87b43b160520e1d2f0_XVZpTN4Qsebf in 180.720474ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_3a746cc7ab5c4415b844f69f3d11305f_r2e3GypG1MnT in 181.69136ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":128117}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":1454453}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":127500}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":132730}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":135219}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_7b7f5764552a48a7af2fcbbc8a09143e_3COgv4JNXIVP in 181.176556ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_dcd2e23af99f44fbafa8007212a878c5_tbf60MlfmuyP in 171.306543ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_a6bf6203986f41c59b8de6a4e6d6654f_yjZbF2a96q1T in 177.343296ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_bd28b646c29f4dfaa4406f82e93d590c_bIenm7yfBFIv in 172.808341ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_a123bfc441ec42dc975cdacf35cc9168_H2WVKppAR39N in 177.8991ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_3fa40ca45b1c40edae78da827a9fcd6e_Bjj90M5fEP6V in 184.9103ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":129051}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":294062}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":102959}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_d9ee0a6d3bac401d885a09b6138ab928_uwTQuRilvOfW in 171.549853ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_f33e43be1b0440458cd75d780b8a227f_2z6bYMvXXbWt in 168.445535ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":143725}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":655409}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":712592}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":275974}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_48fe5c9b3b704d98a3961dd0c272d6fd_6L1lNAT2RMhH in 182.154338ms\",\"time\":\"2024-02-03T12:21:45+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":529888}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:45+03:00\",\"took\":2138457}\n",
      "{\"level\":\"info\",\"msg\":\"Created shard langchain_61e6b498cbfa4af7b659b30ba2117a2c_hSA5zi7oJOxB in 584.271s\",\"time\":\"2024-02-03T12:21:46+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-02-03T12:21:46+03:00\",\"took\":74613}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever created successfully.\n"
     ]
    }
   ],
   "source": [
    "retriever = create_retriever(chuncks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.vectorstores.base.VectorStoreRetriever"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='1500           \\n 10          !\\n    5       !\\n                !\\n   \\n  !\\n1 :   2 :      !\\n:   30:1633\\n !', metadata={'source': '../prompts/context.txt'}),\n",
       " Document(page_content='        \\n          \\n       /   \\n         \\n     <<   ? \\n\\n  >>       !\\n  !\\n          \\n          \\n         :  \\n     !', metadata={'source': '../prompts/context.txt'}),\n",
       " Document(page_content='               \\n              \\n  2015 .       -      \\n                      ', metadata={'source': '../prompts/context.txt'}),\n",
       " Document(page_content='         \\n         \\n         \\n  ?    ?    \\n         \\n         \\n', metadata={'source': '../prompts/context.txt'})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/babi/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_map = {\n",
    "#     \"transformer.word_embeddings\": 0,\n",
    "#     \"transformer.word_embeddings_layernorm\": 0,\n",
    "#     \"lm_head\": \"cpu\",\n",
    "#     \"transformer.h\": 0,\n",
    "#     \"transformer.ln_f\": 0,\n",
    "# }\n",
    "\n",
    "\n",
    "def load_model(model_name, bnb_config):\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    max_memory = f'{23000}MB'\n",
    "\n",
    "#method from the Hugging Face Transformers library to load a pre-trained language model\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\", # dispatch efficiently the model on the available ressources\n",
    "        max_memory = {i: max_memory for i in range(n_gpus)},\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "\n",
    "    # Needed for LLaMA tokenizer\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    return model, tokenizer\n",
    "    \n",
    "    \n",
    "    initialize_agent\n",
    "''' This function, create_bnb_config(), is designed to create and return a\n",
    "configuration object for quantization using the Bits and Bytes (BNB)\n",
    "quantization scheme. '''\n",
    "def create_bnb_config():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        load_in_8bit_fp32_cpu_offload=True,\n",
    "        llm_int8_enable_fp32_cpu_offload=True\n",
    "\n",
    "    )\n",
    "\n",
    "    return bnb_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m bnb_config \u001b[38;5;241m=\u001b[39m create_bnb_config()\n\u001b[0;32m----> 4\u001b[0m model, tokenizer2 \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbnb_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 15\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_name, bnb_config)\u001b[0m\n\u001b[1;32m     12\u001b[0m     max_memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m23000\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mMB\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#method from the Hugging Face Transformers library to load a pre-trained language model\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# dispatch efficiently the model on the available ressources\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_gpus\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, use_auth_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Needed for LLaMA tokenizer\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tenx_week7/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:484\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    483\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tenx_week7/lib/python3.11/site-packages/transformers/modeling_utils.py:2819\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2815\u001b[0m         device_map_without_lm_head \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   2816\u001b[0m             key: device_map[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m modules_to_not_convert\n\u001b[1;32m   2817\u001b[0m         }\n\u001b[1;32m   2818\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m-> 2819\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2820\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2821\u001b[0m \u001b[38;5;124;03m                Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\u001b[39;00m\n\u001b[1;32m   2822\u001b[0m \u001b[38;5;124;03m                the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\u001b[39;00m\n\u001b[1;32m   2823\u001b[0m \u001b[38;5;124;03m                these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\u001b[39;00m\n\u001b[1;32m   2824\u001b[0m \u001b[38;5;124;03m                `device_map` to `from_pretrained`. Check\u001b[39;00m\n\u001b[1;32m   2825\u001b[0m \u001b[38;5;124;03m                https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\u001b[39;00m\n\u001b[1;32m   2826\u001b[0m \u001b[38;5;124;03m                for more details.\u001b[39;00m\n\u001b[1;32m   2827\u001b[0m \u001b[38;5;124;03m                \"\"\"\u001b[39;00m\n\u001b[1;32m   2828\u001b[0m             )\n\u001b[1;32m   2829\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m device_map_without_lm_head\n\u001b[1;32m   2831\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: \n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        "
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "bnb_config = create_bnb_config()\n",
    "model, tokenizer2 = load_model(model_name, bnb_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer2,\n",
    "    use_cache=True,\n",
    "    device_map=\"auto\",\n",
    "    max_length=2048,\n",
    "    do_sample=True,\n",
    "    top_k=5,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer2.eos_token_id,\n",
    "    pad_token_id=tokenizer2.eos_token_id,\n",
    ")\n",
    "\n",
    "# specify the llm\n",
    "llm = HuggingFacePipeline(pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create langchain executor agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def get_link_data(link: str) -> List:\n",
    "    \"\"\"\"\"\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_agent_executor():\n",
    "    with open(\"../prompts/system_message.txt\", \"r\") as file:\n",
    "        system_message = file.read()\n",
    "\n",
    "    agent_kwargs = {\n",
    "    \"system_message\": SystemMessage(content=system_message),\n",
    "    \"retriever\": retriever  # Pass the retriever to the agent\n",
    "    }\n",
    "\n",
    "    llm_agent = initialize_agent(\n",
    "        llm=llm,\n",
    "        # agent=AgentType.OPENAI_FUNCTIONS,\n",
    "        tools=[get_link_data],\n",
    "        agent_kwargs=agent_kwargs,\n",
    "        verbose=True,\n",
    "        max_iterations=20,\n",
    "        early_stopping_method='generate'\n",
    "    )\n",
    "\n",
    "    return llm_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_agent = get_agent_executor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_agent.run(\"    ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenx_week7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
